# yaml-language-server: $schema=https://json.schemastore.org/github-workflow.json
name: Multi-Architecture Docker Manifest Build Template

# Concurrency removed - let groups run in parallel with explicit dependencies
# Resource protection handled by max-parallel limits within each template call

on:
  workflow_call:
    inputs:
      workflow_name:
        description: 'Name of the workflow (e.g., Alpine, Debian)'
        required: true
        type: string
      supported_architectures:
        description: 'JSON array of supported architectures'
        required: true
        type: string
      image_directories:
        description: 'JSON array of image directories to build'
        required: true
        type: string
      target_branch:
        description: 'Target branch for automated builds'
        required: false
        type: string
        default: 'manifest'
      registry:
        description: 'Docker registry'
        required: false
        type: string
        default: 'docker.io'
      repo_name:
        description: 'Repository name'
        required: false
        type: string
        default: 'imresamu'
      image_name:
        description: 'Base image name'
        required: false
        type: string
        default: 'postgistest'
      schedule_parallel:
        description: 'Max parallel builds for scheduled runs'
        required: false
        type: number
        default: 8
      manual_parallel:
        description: 'Max parallel builds for manual (workflow_dispatch) runs'
        required: false
        type: number
        default: 6
      push_pr_parallel:
        description: 'Max parallel builds for push/PR runs'
        required: false
        type: number
        default: 4
      workflow_cache_id:
        description: 'Unique 3-character workflow cache identifier (alp, deb, dev)'
        required: true
        type: string
      cache_registry:
        description: 'Cache registry (ghcr.io, etc.)'
        required: false
        type: string
        default: 'ghcr.io'
      cache_repo_owner:
        description: 'Cache repository owner (must be lowercase, defaults to repo_name)'
        required: false
        type: string
      cache_image_name:
        description: 'Cache image base name (defaults to image_name-cache)'
        required: false
        type: string
    secrets:
      DOCKERHUB_USERNAME:
        required: true
      DOCKERHUB_ACCESS_TOKEN:
        required: true

defaults:
  run:
    shell: bash

env:
  DOCKER_BUILDKIT: '1'
  REGISTRY: ${{ inputs.registry }}
  REPO_NAME: ${{ inputs.repo_name }}
  IMAGE_NAME: ${{ inputs.image_name }}
  TARGET_BRANCH: ${{ inputs.target_branch }}
  WORKFLOW_CACHE_ID: ${{ inputs.workflow_cache_id }}

  # Define supported architectures from input
  SUPPORTED_ARCHITECTURES: ${{ inputs.supported_architectures }}

  # Define architecture to runner mapping - all architectures defined for easy expansion
  ARCH_RUNNERS: '{
    "amd64":    "ubuntu-24.04",
    "arm64":    "ubuntu-24.04-arm",
    "armv6":    "ubuntu-24.04-arm",
    "armv7":    "ubuntu-24.04-arm",
    "386":      "ubuntu-24.04",
    "mips64le": "ubuntu-24.04",
    "ppc64le":  "ubuntu-24.04",
    "riscv64":  "ubuntu-24.04",
    "s390x":    "ubuntu-24.04"
  }'

  # Define architecture to Docker platform mapping - all architectures defined for easy expansion
  ARCH_PLATFORMS: '{
    "amd64":    "linux/amd64",
    "arm64":    "linux/arm64",
    "armv6":    "linux/arm/v6",
    "armv7":    "linux/arm/v7",
    "386":      "linux/386",
    "mips64le": "linux/mips64le",
    "ppc64le":  "linux/ppc64le",
    "riscv64":  "linux/riscv64",
    "s390x":    "linux/s390x"

  }'

  # Define architecture emoji mapping for better job visibility
  ARCH_EMOJIS: '{
    "amd64":    "ðŸ’»",
    "arm64":    "ðŸ’ª",
    "armv6":    "ðŸ¦¾",
    "armv7":    "ðŸ¤–",
    "386":      "ðŸ–¥ï¸",
    "mips64le": "ðŸŽ¯",
    "ppc64le":  "âš¡",
    "riscv64":  "ðŸ§©",
    "s390x":    "ðŸ¢"
  }'

  # Define regression testing mode per architecture
  # Production architectures (amd64, arm64): require - tests must pass
  # Development/experimental architectures: test - tests run but won't fail build
  # JIT-incompatible architectures: test_nojit - tests with JIT disabled
  # Most problematic architectures: skip - no regression tests at all
  # JIT-incompatible + skip tests: skip_nojit - no tests but JIT disabled for end users
  ARCH_REGRESSION_MODES: '{
    "amd64":    "require",
    "arm64":    "require",
    "armv6":    "test_nojit",
    "armv7":    "test_nojit",
    "386":      "test",
    "mips64le": "skip_nojit",
    "ppc64le":  "test_nojit",
    "riscv64":  "test_nojit",
    "s390x":    "skip_nojit"
  }'

  # Define regression mode emoji mapping
  REGRESSION_MODE_EMOJIS: '{
    "skip":       "ðŸ’¨",
    "test":       "ðŸ”",
    "require":    "ðŸ”’",
    "test_nojit": "ðŸ”ðŸ¢",
    "skip_nojit": "ðŸ’¨ðŸ¢"
  }'

  # Define build type emoji mapping (native vs QEMU)
  BUILD_TYPE_EMOJIS: '{
    "native": "âš¡",
    "qemu":   "ðŸ”„"
  }'

  # Define native build detection (runner architecture matches target architecture)
  ARCH_NATIVE_BUILDS: '{
    "amd64":    "native",
    "arm64":    "native",
    "armv6":    "qemu",
    "armv7":    "qemu",
    "386":      "qemu",
    "mips64le": "qemu",
    "ppc64le":  "qemu",
    "riscv64":  "qemu",
    "s390x":    "qemu"
  }'

  # Define optimization flags per architecture (following PostGIS CI script style)
  # Production architectures (amd64, arm64): -O3 with compiler warnings for maximum performance
  # Experimental architectures: -O1 with compiler warnings for build stability
  # Note: -Werror removed to prevent build failures from PostGIS warnings
  ARCH_OPTIMIZATION_FLAGS: '{
    "amd64":    "-O3 -Wall -fno-omit-frame-pointer",
    "arm64":    "-O3 -Wall -fno-omit-frame-pointer",
    "armv6":    "-O1 -Wall -fno-omit-frame-pointer",
    "armv7":    "-O1 -Wall -fno-omit-frame-pointer",
    "386":      "-O1 -Wall -fno-omit-frame-pointer",
    "mips64le": "-O1 -Wall -fno-omit-frame-pointer",
    "ppc64le":  "-O1 -Wall -fno-omit-frame-pointer",
    "riscv64":  "-O1 -Wall -fno-omit-frame-pointer",
    "s390x":    "-O1 -Wall -fno-omit-frame-pointer"
  }'

  # Define LTO (Link Time Optimization) per architecture
  # Production architectures: LTO enabled for maximum performance
  # Experimental architectures: LTO disabled for build stability
  ARCH_LTO_FLAGS: '{
    "amd64":    "--enable-lto",
    "arm64":    "--enable-lto",
    "armv6":    "",
    "armv7":    "",
    "386":      "",
    "mips64le": "",
    "ppc64le":  "",
    "riscv64":  "",
    "s390x":    ""
  }'

  # Define image directories from input
  IMAGE_DIRECTORIES: ${{ inputs.image_directories }}

  # Define Docker cache repository from inputs
  # NOTE: Repository name must be lowercase for Docker registry compatibility
  CACHE_REPO: ${{ inputs.cache_registry }}/${{ inputs.cache_repo_owner || inputs.repo_name }}/${{ inputs.cache_image_name || format('{0}-cache', inputs.image_name) }}
  # ISO week will be calculated in job steps using current time


jobs:
  prepare-matrix:
    name: "ðŸŒ Prepare Matrix | ${{ inputs.workflow_name }}"
    runs-on: ubuntu-24.04
    outputs:
      matrix: ${{ steps.generate-matrix.outputs.matrix }}
      architectures: ${{ env.SUPPORTED_ARCHITECTURES }}
      image_dirs: ${{ env.IMAGE_DIRECTORIES }}
      should_push: ${{ steps.check-conditions.outputs.should_push }}
    steps:
    - name: Check push conditions
      id: check-conditions
      run: |
        if [[ "${{ github.ref }}" == "refs/heads/${{ env.TARGET_BRANCH }}" || "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          echo "should_push=true" >> $GITHUB_OUTPUT
        else
          echo "should_push=false" >> $GITHUB_OUTPUT
        fi
        echo "Push condition result: $(cat $GITHUB_OUTPUT | grep should_push)"

    - name: Generate build matrix
      id: generate-matrix
      run: |
        IMAGES='${{ env.IMAGE_DIRECTORIES }}'
        ARCHITECTURES='${{ env.SUPPORTED_ARCHITECTURES }}'
        ARCH_RUNNERS='${{ env.ARCH_RUNNERS }}'
        ARCH_PLATFORMS='${{ env.ARCH_PLATFORMS }}'
        ARCH_EMOJIS='${{ env.ARCH_EMOJIS }}'
        ARCH_REGRESSION_MODES='${{ env.ARCH_REGRESSION_MODES }}'
        REGRESSION_MODE_EMOJIS='${{ env.REGRESSION_MODE_EMOJIS }}'
        BUILD_TYPE_EMOJIS='${{ env.BUILD_TYPE_EMOJIS }}'
        ARCH_NATIVE_BUILDS='${{ env.ARCH_NATIVE_BUILDS }}'
        ARCH_OPTIMIZATION_FLAGS='${{ env.ARCH_OPTIMIZATION_FLAGS }}'
        ARCH_LTO_FLAGS='${{ env.ARCH_LTO_FLAGS }}'

        MATRIX_JSON='{"include":[]}'

        for image_dir in $(echo "$IMAGES" | jq -r '.[]'); do
          for arch in $(echo "$ARCHITECTURES" | jq -r '.[]'); do
            runner=$(echo "$ARCH_RUNNERS" | jq -r ".[\"$arch\"]")
            platform=$(echo "$ARCH_PLATFORMS" | jq -r ".[\"$arch\"]")
            emoji=$(echo "$ARCH_EMOJIS" | jq -r ".[\"$arch\"]")
            regression_mode=$(echo "$ARCH_REGRESSION_MODES" | jq -r ".[\"$arch\"]")
            regression_emoji=$(echo "$REGRESSION_MODE_EMOJIS" | jq -r ".[\"$regression_mode\"]")
            build_type=$(echo "$ARCH_NATIVE_BUILDS" | jq -r ".[\"$arch\"]")
            build_type_emoji=$(echo "$BUILD_TYPE_EMOJIS" | jq -r ".[\"$build_type\"]")
            optimization_flags=$(echo "$ARCH_OPTIMIZATION_FLAGS" | jq -r ".[\"$arch\"]")
            lto_flags=$(echo "$ARCH_LTO_FLAGS" | jq -r ".[\"$arch\"]")

            ENTRY=$(jq -n \
              --arg image_dir "$image_dir" \
              --arg arch "$arch" \
              --arg runner "$runner" \
              --arg platform "$platform" \
              --arg emoji "$emoji" \
              --arg regression_mode "$regression_mode" \
              --arg regression_emoji "$regression_emoji" \
              --arg build_type "$build_type" \
              --arg build_type_emoji "$build_type_emoji" \
              --arg optimization_flags "$optimization_flags" \
              --arg lto_flags "$lto_flags" \
              '{
                image_dir: $image_dir,
                arch_variant: $arch,
                runner: $runner,
                target: $platform,
                arch_emoji: $emoji,
                regression_mode: $regression_mode,
                regression_emoji: $regression_emoji,
                build_type: $build_type,
                build_type_emoji: $build_type_emoji,
                optimization_flags: $optimization_flags,
                lto_flags: $lto_flags
              }')

            MATRIX_JSON=$(echo "$MATRIX_JSON" | jq ".include += [$ENTRY]")
          done
        done

        echo "matrix<<EOF" >> $GITHUB_OUTPUT
        echo "$MATRIX_JSON" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT
        echo "Generated matrix:"
        echo "$MATRIX_JSON" | jq '.'

    # Cache validation (Completed July 2025):
    # âœ… Cache write conflicts resolved with workflow_cache_id
    # âœ… Format: ${cache_registry}/${cache_repo_owner}/${cache_image_name}-${arch}:${workflow_id}-${family}-${pg}-${week}
    # âœ… Each workflow writes to unique cache namespace (alp/deb/dev)
    # âœ… Matrix parallelism safe - no cache tag collisions possible

  build-images:
    name: "${{ matrix.arch_emoji }}${{ matrix.arch_variant }}|${{ matrix.regression_emoji }}${{ matrix.image_dir }}${{ matrix.build_type_emoji }}"
    needs: prepare-matrix
    runs-on: ${{ matrix.runner }}
    continue-on-error: false
    strategy:
      fail-fast: true
      max-parallel: ${{ github.event_name == 'schedule' && inputs.schedule_parallel || github.event_name == 'workflow_dispatch' && inputs.manual_parallel || inputs.push_pr_parallel }}
      matrix: ${{ fromJson(needs.prepare-matrix.outputs.matrix) }}

    steps:
    - name: Debug - Check matrix variables and cache configuration
      run: |
        echo "=== Matrix Debug Information ==="
        echo "Architecture: ${{ matrix.arch_variant }}"
        echo "Build type: ${{ matrix.build_type }}"
        echo "Target platform: ${{ matrix.target }}"
        echo "Regression mode: ${{ matrix.regression_mode }}"
        echo "Runner: ${{ matrix.runner }}"
        echo "Should run QEMU setup: ${{ matrix.build_type == 'qemu' }}"
        echo ""
        echo "=== Cache Configuration Debug ==="
        echo "Workflow Cache ID: ${{ env.WORKFLOW_CACHE_ID }}"
        echo "Image Directory: ${{ matrix.image_dir }}"
        echo "Cache Repository: ${{ env.CACHE_REPO }}"
        echo "ISO Week: (calculated in build steps)"
        echo ""
        echo "=== Cache Image Names (will be computed in Build step) ==="
        echo "Architecture: ${{ matrix.arch_variant }}"
        echo "Base Cache Repo: ${{ env.CACHE_REPO }}-${{ matrix.arch_variant }}"
        echo "Cache Format: {CACHE_REPO}-{ARCH}:{WORKFLOW_ID}-{FAMILY}-{PG_MAJOR}-{WEEK}"
        echo "================================"

    - name: Checkout source
      uses: actions/checkout@v4

    - name: Set up QEMU for cross-platform builds
      if: ${{ matrix.build_type == 'qemu' }}
      uses: docker/setup-qemu-action@v3
      with:
        platforms: ${{ matrix.target }}

    - name: Set up Docker Buildx (container driver with QEMU support)
      uses: docker/setup-buildx-action@v3
      with:
        install: true
        driver: docker-container
        driver-opts: |
          network=host
        buildkitd-flags: >
          --allow-insecure-entitlement network.host
        platforms: ${{ matrix.target }}

    - name: Bootstrap Buildx builder to load QEMU handlers
      if: ${{ matrix.build_type == 'qemu' }}
      run: docker buildx inspect --bootstrap

    - name: Install build dependencies
      run: |
        set -x
        pip3 install --upgrade pip lastversion check-jsonschema
        tools/environment_init.sh

    - name: Check Docker Hub credentials
      if: ${{ needs.prepare-matrix.outputs.should_push == 'true' }}
      run: |
        set -x
        [[ -n "${{ secrets.DOCKERHUB_USERNAME }}" ]] || { echo "DOCKERHUB_USERNAME missing"; exit 1; }
        [[ -n "${{ secrets.DOCKERHUB_ACCESS_TOKEN }}" ]] || { echo "DOCKERHUB_ACCESS_TOKEN missing"; exit 1; }

    - name: Login to Docker Hub
      uses: docker/login-action@v3
      if: ${{ needs.prepare-matrix.outputs.should_push == 'true' }}
      with:
        username: ${{ secrets.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_ACCESS_TOKEN }}

    - name: Login to GHCR for cache
      uses: docker/login-action@v3
      with:
        registry: ghcr.io
        username: ${{ github.repository_owner }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Read tags from directory
      id: read-tags
      run: |
        set -x
        TAGS_FILE="${{ matrix.image_dir }}/tags"
        [[ -f "$TAGS_FILE" ]] || { echo "Tags file not found: $TAGS_FILE"; exit 1; }
        cat "$TAGS_FILE"
        TAGS=$(cat "$TAGS_FILE" | tr ' ' '\n' | sed '/^$/d' | jq -R . | jq -s . | jq -c .)
        echo "tags<<EOF" >> $GITHUB_OUTPUT
        echo "$TAGS" >> $GITHUB_OUTPUT
        echo "EOF" >> $GITHUB_OUTPUT

    - name: Generate Docker build tags
      id: generate-tags
      run: |
        set -x
        TAGS_JSON='${{ steps.read-tags.outputs.tags }}'

        # Generate short tags for building (avoid Docker tag length issues)
        SHORT_TAGS=""
        FINAL_TAGS=""

        for tag in $(echo "$TAGS_JSON" | jq -r '.[]'); do
          SHORT_TAG=$(echo "$tag" | cut -d'-' -f1)
          SHORT_IMAGE="${{ env.IMAGE_NAME }}-${{ matrix.arch_variant }}:${SHORT_TAG}"
          FULL_TAG="${{ env.REGISTRY }}/${{ env.REPO_NAME }}/${{ env.IMAGE_NAME }}-${{ matrix.arch_variant }}:${tag}"

          [[ -z "$SHORT_TAGS" ]] && SHORT_TAGS="$SHORT_IMAGE" || SHORT_TAGS="$SHORT_TAGS,$SHORT_IMAGE"
          [[ -z "$FINAL_TAGS" ]] && FINAL_TAGS="$FULL_TAG" || FINAL_TAGS="$FINAL_TAGS,$FULL_TAG"
        done

        echo "short_tags=$SHORT_TAGS" >> $GITHUB_OUTPUT
        echo "final_tags=$FINAL_TAGS" >> $GITHUB_OUTPUT
        echo "Generated short build tags:"
        echo "$SHORT_TAGS" | tr ',' '\n'
        echo "Generated final push tags:"
        echo "$FINAL_TAGS" | tr ',' '\n'

    # Cache strategy (Updated July 2025):
    # - Workflow isolation: Each workflow (alp/deb/dev) has unique cache namespace
    # - Architecture isolation: Each arch writes to separate cache repository
    # - PostgreSQL isolation: Each PG major version has unique cache tag
    # - Week-based rotation: ISO week provides automatic cache cleanup
    # - Format: ${workflow_id}-${family}-${pg}-${week}
    # - Read cache: Broad sharing within workflow+arch+family
    # - Write cache: Unique per workflow+arch+family+pg+week
    # - Result: No cache conflicts even with maximum parallel workflows

    - name: Calculate ISO week tags
      id: iso-weeks
      run: |
        # Calculate current and previous ISO week using current time
        CURRENT_WEEK=$(date -u +%G-W%V)
        PREV_WEEK=$(date -u -d "7 days ago" +%G-W%V)
        
        echo "current_week=$CURRENT_WEEK" >> $GITHUB_OUTPUT
        echo "prev_week=$PREV_WEEK" >> $GITHUB_OUTPUT
        echo "Current ISO week: $CURRENT_WEEK"
        echo "Previous ISO week: $PREV_WEEK"

    - name: Debug - Cache tags and configuration
      run: |
        # Extract cache variables (same logic as Build step)
        ARCH="${{ matrix.arch_variant }}"
        FAMILY=$(echo "${{ matrix.image_dir }}" | grep -q alpine && echo "alpine" || echo "debian")
        PG_MAJOR=$(echo "${{ matrix.image_dir }}" | cut -d'-' -f1)
        
        echo "=== ISO Week Calculation Debug ==="
        echo "Current ISO Week: ${{ steps.iso-weeks.outputs.current_week }}"
        echo "Previous ISO Week: ${{ steps.iso-weeks.outputs.prev_week }}"
        echo ""
        echo "=== Cache Debug Information ==="
        echo "Workflow Cache ID: ${{ env.WORKFLOW_CACHE_ID }}"
        echo "Architecture: ${ARCH}"
        echo "Family (detected): ${FAMILY}"
        echo "PostgreSQL Major: pg${PG_MAJOR} (with prefix)"
        echo ""
        echo "=== Generated Cache Image Names ==="
        RW_CACHE="${{ env.CACHE_REPO }}-${ARCH}:${{ env.WORKFLOW_CACHE_ID }}-${FAMILY}-pg${PG_MAJOR}-${{ steps.iso-weeks.outputs.current_week }}"
        PREV_WEEK_CACHE="${{ env.CACHE_REPO }}-${ARCH}:${{ env.WORKFLOW_CACHE_ID }}-${FAMILY}-pg${PG_MAJOR}-${{ steps.iso-weeks.outputs.prev_week }}"
        
        echo "1. Current Week Cache (read+write): ${RW_CACHE}"
        echo "2. Previous Week Cache (fallback): ${PREV_WEEK_CACHE}"
        echo ""
        echo "=== Cache Strategy Summary ==="
        echo "â€¢ Workflow isolation: ${{ env.WORKFLOW_CACHE_ID }} namespace"
        echo "â€¢ Architecture isolation: ${ARCH} repository"
        echo "â€¢ Family isolation: ${FAMILY} tag component"
        echo "â€¢ PostgreSQL isolation: pg${PG_MAJOR} tag component (with prefix)"
        echo "â€¢ Time isolation: ISO week rotation (${{ steps.iso-weeks.outputs.current_week }})"
        echo "â€¢ Read sharing: 2-tier fallback (current week â†’ previous week)"
        echo "â€¢ Write uniqueness: Workflow + arch + family + pg + ISO week"
        echo "â€¢ Cache format: ${ARCH}:workflow-family-pgXX-YYYY-WNN"
        echo "â€¢ Cache retention: Weekly rotation with automatic cleanup"
        echo "================================"

    - name: Build Docker image
      uses: docker/build-push-action@v6
      env:
        ARCH: ${{ matrix.arch_variant }}                               # amd64, arm64 â€¦
        # Extract distro and PG major from the directory name
        FAMILY: ${{ contains(matrix.image_dir, 'alpine') && 'alpine' || 'debian' }}
        PG_MAJOR: ${{ startsWith(matrix.image_dir, '13-') && '13' || startsWith(matrix.image_dir, '14-') && '14' || startsWith(matrix.image_dir, '15-') && '15' || startsWith(matrix.image_dir, '16-') && '16' || startsWith(matrix.image_dir, '17-') && '17' || startsWith(matrix.image_dir, '18-') && '18' || '17' }}                # "16" in 16-3.3/alpine3.21
        # Current week cache (read + write)
        RW_CACHE: ${{ env.CACHE_REPO }}-${{ matrix.arch_variant }}:${{ env.WORKFLOW_CACHE_ID }}-${{ contains(matrix.image_dir, 'alpine') && 'alpine' || 'debian' }}-pg${{ startsWith(matrix.image_dir, '13-') && '13' || startsWith(matrix.image_dir, '14-') && '14' || startsWith(matrix.image_dir, '15-') && '15' || startsWith(matrix.image_dir, '16-') && '16' || startsWith(matrix.image_dir, '17-') && '17' || startsWith(matrix.image_dir, '18-') && '18' || '17' }}-${{ steps.iso-weeks.outputs.current_week }}
        # Previous ISO week cache for fallback (read-only)
        RO_CACHE_PREV1W: ${{ env.CACHE_REPO }}-${{ matrix.arch_variant }}:${{ env.WORKFLOW_CACHE_ID }}-${{ contains(matrix.image_dir, 'alpine') && 'alpine' || 'debian' }}-pg${{ startsWith(matrix.image_dir, '13-') && '13' || startsWith(matrix.image_dir, '14-') && '14' || startsWith(matrix.image_dir, '15-') && '15' || startsWith(matrix.image_dir, '16-') && '16' || startsWith(matrix.image_dir, '17-') && '17' || startsWith(matrix.image_dir, '18-') && '18' || '17' }}-${{ steps.iso-weeks.outputs.prev_week }}

      with:
        context: ${{ matrix.image_dir }}
        file: ${{ matrix.image_dir }}/Dockerfile
        platforms: ${{ matrix.target }}
        push: false
        pull: true
        load: true
        tags: ${{ steps.generate-tags.outputs.short_tags }}
        build-args: |
          BUILDKIT_INLINE_CACHE=1
          PGIS1_REGRESSION_MODE=${{ matrix.regression_mode }}
          PGIS1_OPTIMIZATION_FLAGS=${{ matrix.optimization_flags }}
          PGIS1_LTO_FLAGS=${{ matrix.lto_flags }}
          REGISTRY=${{ contains(matrix.image_dir, 'bundle') && env.REGISTRY || '' }}
          REPO_NAME=${{ contains(matrix.image_dir, 'bundle') && env.REPO_NAME || '' }}
          IMAGE_NAME=${{ env.IMAGE_NAME }}-${{ matrix.arch_variant }}
        cache-from: |
          type=registry,ref=${{ env.RW_CACHE }}
          type=registry,ref=${{ env.RO_CACHE_PREV1W }}
        cache-to: |
          type=registry,ref=${{ env.RW_CACHE }},mode=max,compression=zstd
        provenance: false
        sbom: false

    - name: Debug - Cache operation results
      run: |
        # Extract cache variables (same logic as previous debug step)
        ARCH="${{ matrix.arch_variant }}"
        FAMILY=$(echo "${{ matrix.image_dir }}" | grep -q alpine && echo "alpine" || echo "debian")
        PG_MAJOR=$(echo "${{ matrix.image_dir }}" | cut -d'-' -f1)
        
        RW_CACHE="${{ env.CACHE_REPO }}-${ARCH}:${{ env.WORKFLOW_CACHE_ID }}-${FAMILY}-pg${PG_MAJOR}-${{ steps.iso-weeks.outputs.current_week }}"
        PREV_WEEK_CACHE="${{ env.CACHE_REPO }}-${ARCH}:${{ env.WORKFLOW_CACHE_ID }}-${FAMILY}-pg${PG_MAJOR}-${{ steps.iso-weeks.outputs.prev_week }}"
        
        echo "=== Cache Operation Results ==="
        echo "Build completed for: ${{ matrix.image_dir }} on ${{ matrix.arch_variant }}"
        echo "ISO Weeks: Current=${{ steps.iso-weeks.outputs.current_week }}, Previous=${{ steps.iso-weeks.outputs.prev_week }}"
        echo ""
        echo "=== Cache Images Used During Build ==="
        echo "1. Current week cache (read+write): ${RW_CACHE}"
        echo "2. Previous week cache (fallback): ${PREV_WEEK_CACHE}"
        echo ""
        echo "=== Cache Strategy Details ==="
        echo "â€¢ PostgreSQL Version: pg${PG_MAJOR} (with prefix for clarity)"
        echo "â€¢ Cache Write Target: ${RW_CACHE}"
        echo "â€¢ Cache Read Sources: 2-tier fallback strategy"
        echo "â€¢ Cache Retention: Weekly rotation prevents stale caches"
        echo ""
        echo "=== Cache Hit/Miss Analysis ==="
        echo "Note: Detailed cache statistics are available in the Build Docker image step logs"
        echo "Look for 'CACHED' vs 'DONE' indicators in buildkit output above"
        echo ""
        echo "=== Cache Repository Status ==="
        echo "Attempting to verify cache repository exists..."
        # Try to inspect the cache repository (will fail gracefully if not accessible)
        docker buildx imagetools inspect "${RO_CACHE}" 2>/dev/null && echo "âœ… Read cache repository accessible" || echo "â„¹ï¸  Read cache repository not found (expected on first run)"
        echo ""
        echo "=== Build Success Confirmation ==="
        echo "âœ… Docker build completed successfully"
        echo "âœ… Cache write to ${RW_CACHE} should have occurred"
        echo "âœ… Future builds will benefit from this cache layer"
        echo "================================"

    - name: List docker images with architecture info
      run: ./tools/list-docker-images.sh postgistest

    - name: Ensure QEMU for testing
      if: ${{ matrix.build_type == 'qemu' }}
      uses: docker/setup-qemu-action@v3
      with:
        platforms: ${{ matrix.target }}

    - name: Test built image with official test suite
      env:
        # Disable buildx for all architectures during testing to ensure postgres-initdb test works
        # The postgres-initdb test needs to find local images, not pull from registry
        DOCKER_BUILDKIT: '0'
        DOCKER_DEFAULT_PLATFORM: ${{ matrix.target }}
        PLATFORM: ${{ matrix.target }}
        BUILDX_PLATFORMS: ${{ matrix.target }}
        # Buildx/qemu test need more time for the official postgres test
        # These variables are used by docker-library/official-images test framework
        # See: https://github.com/docker-library/official-images/blob/master/test/tests/postgres-basics/run.sh
        # Usage: retry.sh --tries "$POSTGRES_TEST_TRIES" --sleep "$POSTGRES_TEST_SLEEP" "echo 'SELECT 1' | psql"
        POSTGRES_TEST_TRIES: 60  # Maximum retry attempts for PostgreSQL connection tests
        POSTGRES_TEST_SLEEP: 2   # Sleep seconds between retry attempts
      run: |
        set -x
        FIRST_TAG=$(echo '${{ steps.read-tags.outputs.tags }}' | jq -r '.[0]')
        SHORT_TAG=$(echo "$FIRST_TAG" | cut -d'-' -f1)
        SHORT_TEST_IMAGE="${{ env.IMAGE_NAME }}-${{ matrix.arch_variant }}:${SHORT_TAG}"

        echo "Testing for ${{ matrix.target }} (build type: ${{ matrix.build_type_emoji }})"
        echo "Testing short image: $SHORT_TEST_IMAGE"
        echo "Using DOCKER_BUILDKIT=$DOCKER_BUILDKIT for testing compatibility"
        echo "Using DOCKER_DEFAULT_PLATFORM=$DOCKER_DEFAULT_PLATFORM"
        echo "Using PLATFORM=$PLATFORM"
        echo "Using BUILDX_PLATFORMS=$BUILDX_PLATFORMS"
        echo "PostgreSQL test configuration: POSTGRES_TEST_TRIES=$POSTGRES_TEST_TRIES, POSTGRES_TEST_SLEEP=$POSTGRES_TEST_SLEEP"

        git clone --depth 1 https://github.com/docker-library/official-images.git

        [[ -f "./official-images/test/run.sh" ]] || { echo "./official-images/test/run.sh not found"; exit 1; }
        [[ -f "./test/postgis-config.sh" ]] || { echo "./test/postgis-config.sh not found"; exit 1; }
        [[ -f "./official-images/test/config.sh" ]] || { echo "./official-images/test/config.sh not found"; exit 1; }

        # Quick platform test for all architectures
        docker run --rm --platform ${{ matrix.target }} "$SHORT_TEST_IMAGE" echo "Platform test successful" || {
          echo "Platform test failed, but continuing with official tests"
        }

        # Verify image is accessible for postgres-initdb test
        echo "Verifying docker inspect for postgres-initdb test:"
        docker inspect "$SHORT_TEST_IMAGE" > /dev/null && echo "âœ“ docker inspect successful" || echo "âœ— docker inspect failed"

        # Additional debugging for postgres-initdb issue
        echo "Available images matching pattern:"
        docker images | grep postgistest || echo "No postgistest images found"

        # Create test configuration for short image name
        export REGISTRY=""
        export REPO_NAME=""
        export IMAGE_NAME="${{ env.IMAGE_NAME }}-${{ matrix.arch_variant }}"

        # Run official test suite with short image name
        ./official-images/test/run.sh -c ./official-images/test/config.sh -c test/postgis-config.sh "$SHORT_TEST_IMAGE"

    - name: Tag and push Docker images
      if: ${{ needs.prepare-matrix.outputs.should_push == 'true' }}
      run: |
        set -x
        # Get short and final tags
        SHORT_TAGS='${{ steps.generate-tags.outputs.short_tags }}'
        FINAL_TAGS='${{ steps.generate-tags.outputs.final_tags }}'

        # Convert comma-separated lists to arrays
        IFS=',' read -ra SHORT_ARRAY <<< "$SHORT_TAGS"
        IFS=',' read -ra FINAL_ARRAY <<< "$FINAL_TAGS"

        # Tag each short image with final names and push
        for i in "${!SHORT_ARRAY[@]}"; do
          SHORT_TAG="${SHORT_ARRAY[i]}"
          FINAL_TAG="${FINAL_ARRAY[i]}"

          echo "Tagging $SHORT_TAG as $FINAL_TAG"
          docker tag "$SHORT_TAG" "$FINAL_TAG"

          echo "Pushing $FINAL_TAG"
          docker push "$FINAL_TAG"
        done

    - name: Verify pushed images - List tagged images with architecture
      if: ${{ needs.prepare-matrix.outputs.should_push == 'true' }}
      run: |
        echo "=== Verifying pushed images ==="
        ./tools/list-docker-images.sh "${{ env.IMAGE_NAME }}-${{ matrix.arch_variant }}"

    - name: Verify pushed images - Check labels for correctness
      if: ${{ needs.prepare-matrix.outputs.should_push == 'true' }}
      run: |
        echo "=== Verifying image labels after push ==="
        FIRST_TAG=$(echo '${{ steps.read-tags.outputs.tags }}' | jq -r '.[0]')
        SHORT_TAG=$(echo "$FIRST_TAG" | cut -d'-' -f1)
        SHORT_IMAGE="${{ env.IMAGE_NAME }}-${{ matrix.arch_variant }}:${SHORT_TAG}"

        echo "Checking labels for: $SHORT_IMAGE"
        ./tools/list-docker-labels.sh "$SHORT_IMAGE"

        echo ""
        echo "=== IMPORTANT: Verify the following ==="
        echo "1. Labels should contain correct version information"
        echo "2. org.opencontainers.image.* labels should be present"
        echo "3. org.postgis.base.* labels should be present"
        echo "4. maintainer label should be correct"
        echo "5. For bundle images: description should mention 'Bundle'"
        echo "6. Image architecture should match build target: ${{ matrix.target }}"

    - name: Debug - Final cache summary
      run: |
        # Extract cache variables for final summary
        ARCH="${{ matrix.arch_variant }}"
        FAMILY=$(echo "${{ matrix.image_dir }}" | grep -q alpine && echo "alpine" || echo "debian")
        PG_MAJOR=$(echo "${{ matrix.image_dir }}" | cut -d'-' -f1)
        WEEK_TAG=$(date -u +%G-W%V)
        
        RW_CACHE="${{ env.CACHE_REPO }}-${ARCH}:${{ env.WORKFLOW_CACHE_ID }}-${FAMILY}-pg${PG_MAJOR}-${WEEK_TAG}"
        
        echo "=== Build Job Cache Summary ==="
        echo "Job: ${{ matrix.arch_variant }} | ${{ matrix.image_dir }}"
        echo "Workflow: ${{ env.WORKFLOW_CACHE_ID }} (${{ inputs.workflow_name }})"
        echo "Cache written to: ${RW_CACHE}"
        echo "Status: âœ… Build completed successfully"
        echo ""
        echo "=== Cache Namespace Summary ==="
        echo "Workflow isolation: ${{ env.WORKFLOW_CACHE_ID }}"
        echo "Architecture isolation: ${ARCH}"
        echo "Family isolation: ${FAMILY}"
        echo "PostgreSQL isolation: ${PG_MAJOR}"
        echo "Time isolation: ${WEEK_TAG}"
        echo ""
        echo "=== Next Steps ==="
        echo "â€¢ This cache will be available for future builds"
        echo "â€¢ Cache key: ${{ env.WORKFLOW_CACHE_ID }}-${FAMILY}-${PG_MAJOR}-${WEEK_TAG}"
        echo "â€¢ Cache will automatically expire after 1 week"
        echo "â€¢ Parallel workflows will not conflict with this cache"
        echo "================================"

  create-manifests:
    name: "ðŸ“¦ Create manifests | ${{ inputs.workflow_name }}"
    needs: [prepare-matrix, build-images]
    runs-on: ubuntu-24.04
    if: ${{ needs.prepare-matrix.outputs.should_push == 'true' }}

    steps:
    - name: Checkout source
      uses: actions/checkout@v4

    - name: Login to Docker Hub
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_ACCESS_TOKEN }}


    - name: Create and push multi-architecture manifests
      run: |
        set -x
        IMAGE_DIRS='${{ needs.prepare-matrix.outputs.image_dirs }}'
        ARCHITECTURES='${{ needs.prepare-matrix.outputs.architectures }}'

        for image_dir in $(echo "$IMAGE_DIRS" | jq -r '.[]'); do
          TAGS_FILE="$image_dir/tags"
          [[ -f "$TAGS_FILE" ]] || { echo "Tags file not found: $TAGS_FILE"; exit 1; }

          TAGS=$(cat "$TAGS_FILE" | tr ' ' '\n' | sed '/^$/d' | jq -R . | jq -s . | jq -c .)

          for tag in $(echo "$TAGS" | jq -r '.[]'); do
            MANIFEST_TAG="${{ env.REGISTRY }}/${{ env.REPO_NAME }}/${{ env.IMAGE_NAME }}:${tag}"

            SOURCE_TAGS=""
            for arch in $(echo "$ARCHITECTURES" | jq -r '.[]'); do
              ARCH_TAG="${{ env.REGISTRY }}/${{ env.REPO_NAME }}/${{ env.IMAGE_NAME }}-${arch}:${tag}"
              [[ -z "$SOURCE_TAGS" ]] && SOURCE_TAGS="$ARCH_TAG" || SOURCE_TAGS="$SOURCE_TAGS $ARCH_TAG"
            done

            docker buildx imagetools create -t "$MANIFEST_TAG" $SOURCE_TAGS
            docker buildx imagetools inspect "$MANIFEST_TAG"
          done
        done

    - name: Test manifests
      run: |
        set -x
        IMAGE_DIRS='${{ needs.prepare-matrix.outputs.image_dirs }}'
        ARCHITECTURES='${{ needs.prepare-matrix.outputs.architectures }}'
        EXPECTED_ARCHS=$(echo "$ARCHITECTURES" | jq 'length')

        for image_dir in $(echo "$IMAGE_DIRS" | jq -r '.[]'); do
          FIRST_TAG=$(cat "$image_dir/tags" | tr ' ' '\n' | sed '/^$/d' | head -n1)
          MANIFEST_TAG="${{ env.REGISTRY }}/${{ env.REPO_NAME }}/${{ env.IMAGE_NAME }}:${FIRST_TAG}"

          echo "Checking manifest: $MANIFEST_TAG"
          docker buildx imagetools inspect "$MANIFEST_TAG"
        done


# TODO: - add a step to clean up old images in GHCR
#   ghcr-cleaner ${cache_registry}/${cache_repo_owner}/${cache_image_name}-amd64 \
#              --keep-tag-regex '2025-W(2[6-9]|3[0-9])'   # keep last 4 weeks
#